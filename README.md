# Consumer Staples Forecasting

## ğŸ§  Project Overview
This project develops a **machine learning pipeline to forecast weekly stock returns** and evaluate **trading strategies** in the **Consumer Staples sector**.

The analysis focuses on five major publicly traded companies:
- **NestlÃ© (NESN.SW)**
- **Procter & Gamble (PG)**
- **Unilever (UL)**
- **Coca-Cola (KO)**
- **PepsiCo (PEP)**

Several machine learning models are trained and compared, and their performance is evaluated both **statistically** (out-of-sample prediction accuracy) and **economically** (backtesting and Monte Carlo simulations).

The project follows academic best practices for **time-series modeling**, **data leakage prevention**, and **out-of-sample evaluation**.

---

## ğŸ¯ Objectives
1. Automatically collect historical market data.
2. Clean and preprocess financial time-series data.
3. Engineer predictive features suitable for return forecasting.
4. Train multiple machine learning models (Linear Regression, Neural Network, Random Forest, XGBoost).
5. Evaluate models using a strict temporal train/validation/test split (**70% Train / 20% Validation / 10% Test**).
6. Backtest trading strategies based on model predictions.
7. Assess robustness using Monte Carlo simulations.

---

## ğŸ§° Technologies & Requirements

### System Requirements
- **Python**: 3.12.11
- **Platform**: Nuvolos or Linux-based environment
- **RAM**: Minimum 8GB recommended
- **Disk Space**: ~500MB for data and results

### Core Dependencies
```text
pandas==2.3.2
numpy==2.3.2
scikit-learn==1.7.1
xgboost==3.1.2
matplotlib==3.10.5
scipy==1.16.1
seaborn==0.13.2
yfinance

##ğŸ“ Repository Structure

    
consumer-staples-forecasting/
â”‚
â”œâ”€â”€ main.py                                  # MAIN ENTRY POINT (Runs full pipeline)
â”œâ”€â”€ data/                                    # Data directory
â”‚   â”œâ”€â”€ raw/                                 # Raw downloaded data
â”‚   â”‚   â””â”€â”€ consumer_staples_data.csv
â”‚   â””â”€â”€ processed/                           # Processed splits
â”‚       â”œâ”€â”€ train.csv                        # Training set (70%)
â”‚       â”œâ”€â”€ validation.csv                   # Validation set (20%)
â”‚       â””â”€â”€ test.csv                         # Test set (10%)
â”‚
â”œâ”€â”€ src/                                     # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py                       # Step 1: Data acquisition
â”‚   â”œâ”€â”€ preprocessing.py                     # Step 2: Cleaning & Engineering
â”‚   â”œâ”€â”€ create_train_validation_test_split.py# Step 3: Temporal split + look ahead biais
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ linear_model.py
â”‚   â”‚   â”œâ”€â”€ neural_network.py
â”‚   â”‚   â”œâ”€â”€ random_forest.py
â”‚   â”‚   â”œâ”€â”€ xgboost_model.py
â”‚   â”œâ”€â”€ model_evaluate.py                    # Step 4: Initial evaluation
â”‚   â”œâ”€â”€ train_all.py                         # Step 5: Model training
â”‚   â”œâ”€â”€ test_all.py                          # Step 6: Final testing
â”‚   â”œâ”€â”€ feature_importance.py                # Step 7: Feature analysis
â”‚   â”œâ”€â”€ backtesting.py                       # Step 8: Backtesting strategies
â”‚   â”œâ”€â”€ monte_carlo.py                       # Step 9: Risk simulation
â”‚   â”œâ”€â”€ linear_regression_model.py           # Model class
â”‚   â”œâ”€â”€ neural_network_model.py              # Model class
â”‚   â”œâ”€â”€ random_forest_model.py               # Model class
â”‚   â””â”€â”€ xgboost_model.py                     # Model class
â”‚
â”œâ”€â”€ results/                                 # Generated outputs
â”‚   â”œâ”€â”€ models/                              # Trained models (.pkl)
â”‚   â”œâ”€â”€ figures/                             # Visualizations (.png)
â”‚   â””â”€â”€ metrics/                             # Performance metrics (.csv)
â”‚
â”œâ”€â”€ environment.yml                          # Conda environment specification
â”œâ”€â”€ requirements.txt                         # pip dependencies
â””â”€â”€ README.md                                # This file


##ğŸš€ Setup & Installation

## Installation

To set up the environment, run the following commands:

conda env create 
-f environment.yml -n consumer-staples-forecast

##ğŸ¬ Execution Instructions

python main.py


##ğŸ“Š Expected OutputsAfter running the pipeline, check the results/ folder:
Models: 4 .pkl files in results/models/
Metrics: test_performance.csv (Neural Network is expected to have the highest RÂ² ~0.138)
Figures: Backtesting charts, Monte Carlo histograms, and feature importance plots in results/figures/

ğŸ“„ LicenseAcademic project for Advanced Programming - HEC Lausanne (Fall 2025).
Data sourced from Yahoo Finance.